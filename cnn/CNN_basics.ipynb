{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convolutional neural network",
   "id": "1371204970034f77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CNN operator",
   "id": "65a2ec12f5869ad8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:35:18.627989Z",
     "start_time": "2025-10-14T17:35:18.624532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "cnn = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n",
    "cnn"
   ],
   "id": "53dce14ebd96b73d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Parameters definition",
   "id": "ff9494e86c2650f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:35:18.658553Z",
     "start_time": "2025-10-14T17:35:18.653931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "sobel_filter = torch.tensor([\n",
    "    [1.0, 0, -1.0],\n",
    "    [2.0, 0, -2.0],\n",
    "    [1.0, 0.0, -1.0]\n",
    "])\n",
    "\n",
    "cnn.state_dict()[\"weight\"][0][0] = sobel_filter\n",
    "cnn.state_dict()[\"bias\"][0] = 0.0\n",
    "print(cnn.state_dict())\n",
    "print(cnn.stride)"
   ],
   "id": "8c1fc5bc2139ee32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'weight': tensor([[[[ 1.,  0., -1.],\n",
      "          [ 2.,  0., -2.],\n",
      "          [ 1.,  0., -1.]]]]), 'bias': tensor([0.])})\n",
      "(1, 1)\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Random image (1, 1, 5, 5)\n",
    "\n",
    "each value is within the range of 0-1"
   ],
   "id": "ecb0b21751676fe3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:35:18.681897Z",
     "start_time": "2025-10-14T17:35:18.678584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image = torch.rand(1, 1, 5, 5)\n",
    "print(image)"
   ],
   "id": "1c6c35e6056c6cf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0818, 0.9518, 0.6388, 0.8855, 0.9175],\n",
      "          [0.7224, 0.2819, 0.1139, 0.7374, 0.1604],\n",
      "          [0.3381, 0.4283, 0.3607, 0.1781, 0.5897],\n",
      "          [0.0199, 0.6454, 0.7889, 0.8135, 0.3800],\n",
      "          [0.4610, 0.4480, 0.2179, 0.1930, 0.5393]]]])\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Convolution with the default stride\n",
    "\n",
    "The result has the dimension:\n",
    "$$n_{new}={n-f}+1$$\n",
    "\n",
    "- **n** - order of the input tensor\n",
    "- **f** - order of the filter"
   ],
   "id": "803f81d658596547"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:35:18.705706Z",
     "start_time": "2025-10-14T17:35:18.702385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "z = cnn(image)\n",
    "print(z)"
   ],
   "id": "118b323c8c5358ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.6374, -0.5944, -0.6006],\n",
      "          [-0.2057, -0.1233, -0.0956],\n",
      "          [-1.3176,  0.1688,  0.2675]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Convolution with the stride=2\n",
    "\n",
    "stride=2 leads to:\n",
    "- horizontal move - move 2 values right each time\n",
    "- vertical mode - move 2 values down after finishing row\n",
    "\n",
    "The result has the dimension:\n",
    "$$n_{new}=\\dfrac{n-f}{s}+1$$\n",
    "\n",
    "- **n** - order of the input tensor\n",
    "- **f** - order of the filter\n",
    "- **s** - stride"
   ],
   "id": "ffdec9b5f1720f50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:35:18.727726Z",
     "start_time": "2025-10-14T17:35:18.723646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn_stride2 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=2)\n",
    "z_stride2 = cnn_stride2(image)\n",
    "print(z_stride2)"
   ],
   "id": "3de1df69963ed294",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5372, 0.2895],\n",
      "          [0.1177, 0.2325]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Convolution with the stride=2 and padding=1\n",
    "\n",
    "The result has the dimension:\n",
    "$$n_{new}=\\dfrac{n+2p-f}{s}+1$$\n",
    "\n",
    "- **n** - order of the input tensor\n",
    "- **f** - order of the filter\n",
    "- **s** - stride\n",
    "- **p** - padding"
   ],
   "id": "73f12673e95555cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:35:18.755469Z",
     "start_time": "2025-10-14T17:35:18.751424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn_stride2_padding1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=2)\n",
    "z_stride2_padding1 = cnn(image)\n",
    "print(z_stride2_padding1)"
   ],
   "id": "3971826ea3f6754c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.6374, -0.5944, -0.6006],\n",
      "          [-0.2057, -0.1233, -0.0956],\n",
      "          [-1.3176,  0.1688,  0.2675]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:35:18.775512Z",
     "start_time": "2025-10-14T17:35:18.772831Z"
    }
   },
   "cell_type": "code",
   "source": "## (P.S.) Padding visualization",
   "id": "68ee37d0cf05b64e",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:35:18.799170Z",
     "start_time": "2025-10-14T17:35:18.796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "padded_image = F.pad(image, (1, 1, 1, 1))  # (left, right, top, bottom)\n",
    "print(padded_image)"
   ],
   "id": "755388bf88dc5403",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0818, 0.9518, 0.6388, 0.8855, 0.9175, 0.0000],\n",
      "          [0.0000, 0.7224, 0.2819, 0.1139, 0.7374, 0.1604, 0.0000],\n",
      "          [0.0000, 0.3381, 0.4283, 0.3607, 0.1781, 0.5897, 0.0000],\n",
      "          [0.0000, 0.0199, 0.6454, 0.7889, 0.8135, 0.3800, 0.0000],\n",
      "          [0.0000, 0.4610, 0.4480, 0.2179, 0.1930, 0.5393, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])\n"
     ]
    }
   ],
   "execution_count": 141
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
